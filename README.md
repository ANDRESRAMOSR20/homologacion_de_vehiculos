# üöó Sistema de Homologaci√≥n de Veh√≠culos con IA

Este documento detalla la arquitectura, tecnolog√≠as y decisiones de dise√±o implementadas para el sistema de homologaci√≥n de veh√≠culos.

## üõ†Ô∏è Stack Tecnol√≥gico

### 1. Backend: **Python + FastAPI**
*   **Justificaci√≥n**: Python es el est√°ndar de facto para IA y procesamiento de datos. FastAPI se eligi√≥ por su alto rendimiento (as√≠ncrono), validaci√≥n autom√°tica de datos (Pydantic) y generaci√≥n autom√°tica de documentaci√≥n (Swagger UI).
*   **Uso**: Manejo de la API REST, orquestaci√≥n de servicios y l√≥gica de negocio.

### 2. Base de Datos: **SQLite + SQLAlchemy**
*   **Justificaci√≥n**: Para este MVP, SQLite ofrece simplicidad (sin servidor) y portabilidad. SQLAlchemy (ORM) permite abstraer las consultas SQL, facilitando la migraci√≥n futura a PostgreSQL o MySQL sin cambiar el c√≥digo.
*   **Uso**: Almacenamiento del cat√°logo oficial (`vehicles`) y veh√≠culos de socios (`partner_vehicles`).

### 3. B√∫squeda Vectorial: **FAISS (Facebook AI Similarity Search)**
*   **Justificaci√≥n**: FAISS es una librer√≠a altamente optimizada para b√∫squeda de similitud en vectores densos. Es mucho m√°s eficiente que comparar embeddings uno por uno (fuerza bruta), permitiendo escalar a millones de registros.
*   **Uso**: Indexaci√≥n de los embeddings de los nombres de veh√≠culos oficiales para recuperaci√≥n r√°pida de candidatos (Top-K).

### 4. Embeddings: **SentenceTransformers (all-MiniLM-L6-v2)**
*   **Justificaci√≥n**: Este modelo es un equilibrio perfecto entre velocidad y precisi√≥n sem√°ntica. Genera vectores de 384 dimensiones que capturan el significado del texto, permitiendo encontrar "Mazda 3" aunque se escriba "Mazda3" o "Mzda 3".
*   **Uso**: Conversi√≥n de descripciones de texto a vectores num√©ricos.

### 5. LLM: **OpenAI GPT-4o-mini**
*   **Justificaci√≥n**: A pesar de la b√∫squeda vectorial, existen casos ambiguos (ej. "Mazda 3" vs "Mazdaspeed 3"). Un LLM tiene el "sentido com√∫n" automotriz para distinguir versiones deportivas, a√±os o errores tipogr√°ficos graves que los vectores no captan.
*   **Uso**: Desempate inteligente cuando la confianza de la b√∫squeda vectorial es media o hay m√∫ltiples candidatos muy cercanos.

### 6. Contenedorizaci√≥n: **Docker & Docker Compose**
*   **Justificaci√≥n**: Garantiza que el entorno de ejecuci√≥n sea id√©ntico en desarrollo y producci√≥n, eliminando problemas de dependencias ("en mi m√°quina funciona").
*   **Uso**: Empaquetado de la aplicaci√≥n y sus librer√≠as.

---

## üöß Desaf√≠os y Soluciones

### 1. El Problema de "Mazdaspeed3"
*   **Desaf√≠o**: El sistema no emparejaba "Mazda Mazdaspeed3" con "Mazda 3".
*   **An√°lisis**: Vectorialmente son similares, pero conceptualmente son veh√≠culos distintos (versi√≥n deportiva vs est√°ndar).
*   **Soluci√≥n**: El LLM actu√≥ correctamente al rechazar el match. Esto valid√≥ que el sistema es robusto ante falsos positivos peligrosos.

### 2. Consultas Cortas vs Descripciones Largas
*   **Desaf√≠o**: Una b√∫squeda como "Mazda 3" ten√≠a baja similitud vectorial con "MAZDA MAZDA3 2008 I TOURING..." debido a la diferencia de longitud y palabras extra.
*   **Soluci√≥n**: Implementamos **B√∫squeda H√≠brida**.
    *   Combinamos el puntaje vectorial (sem√°ntico) con un puntaje de **Token Overlap** (Jaccard/Intersecci√≥n).
    *   F√≥rmula: `Score Final = 0.6 * Vector + 0.4 * Overlap`.
    *   Esto prioriz√≥ los resultados que conten√≠an las palabras exactas de la b√∫squeda.

### 3. Contexto del LLM
*   **Desaf√≠o**: Inicialmente, el LLM recib√≠a solo IDs (ej. "M-100") y no pod√≠a decidir.
*   **Soluci√≥n**: Modificamos el `SimilarityService` para devolver tuplas `(id, nombre, score)` y actualizamos el prompt del LLM para incluir los nombres completos de los candidatos.

### 4. Docker Build Lento
*   **Desaf√≠o**: La construcci√≥n de la imagen tardaba mucho y fallaba por tama√±o de contexto.
*   **Soluci√≥n**: Identificamos que se estaba copiando el entorno virtual `veh-env` (gigabytes de archivos). Lo agregamos al `.dockerignore`, reduciendo el contexto a unos pocos megabytes.

---

## üìÇ Estructura del Proyecto

### `src/api/`
*   **`server.py`**: Punto de entrada de la aplicaci√≥n FastAPI.
*   **`controllers/`**: L√≥gica de negocio que conecta la API con los servicios.
*   **`routers/`**: Definici√≥n de endpoints HTTP (`/match`, `/metrics`).

### `src/core/matching/`
*   **`matching_engine.py`**: Orquestador principal. Coordina normalizaci√≥n -> embedding -> b√∫squeda -> LLM.
*   **`similarity_service.py`**: Maneja el √≠ndice FAISS y la l√≥gica de b√∫squeda h√≠brida.
*   **`llm_service.py`**: Cliente de OpenAI para resoluci√≥n de conflictos.
*   **`embedding_service.py`**: Generaci√≥n de vectores con SentenceTransformers.

### `src/core/normalization/`
*   **`normalizer.py`**: Limpieza de texto, eliminaci√≥n de acentos y expansi√≥n de sin√≥nimos (ej. "VW" -> "VOLKSWAGEN").

### `src/core/db/`
*   **`models/`**: Definici√≥n de tablas (`Vehicle`, `PartnerVehicle`).
*   **`migrations/`**: Scripts para carga inicial de datos (`seed_vehicles.py`).

### `scripts/`
*   **`process_partner_vehicles.py`**: Script batch para procesar masivamente veh√≠culos de socios.
*   **`build_vector_index.py`**: Genera el √≠ndice FAISS a partir de la base de datos.
*   **`manual_match.py`**: Herramienta para forzar emparejamientos manualmente.

---

## üöÄ Flujo de "Cat√°logo Unificado"

El sistema implementa una l√≥gica de auto-aprendizaje para veh√≠culos no encontrados:

1.  Se busca el veh√≠culo en el **Cat√°logo Oficial**.
2.  Si hay match -> Se asigna el ID oficial.
3.  Si **NO** hay match -> El sistema **crea autom√°ticamente** una nueva entrada en el cat√°logo con un ID propio (`SOC-XXX`).
4.  Se reconstruye el √≠ndice vectorial para que este nuevo veh√≠culo sea "encontrable" en el futuro.

Esto permite que el cat√°logo crezca org√°nicamente con la informaci√≥n de los socios, manteniendo la integridad de los datos oficiales.
